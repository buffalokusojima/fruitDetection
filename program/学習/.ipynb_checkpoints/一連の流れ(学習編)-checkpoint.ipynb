{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習の準備から学習まで記載"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## １．学習の準備"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### クラスファイル作成\n",
    "\n",
    "学習データのフォルダから作成。今回はフルーツの種類のみを対象に作成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定数宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = '../../data/学習データ/479削除データ'\n",
    "type_dir = os.path.join(target_dir, 'image')\n",
    "class_file = 'type_class.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(type_dir)\n",
    "last = folders[-1].split(\"_\")[1]\n",
    "with open(class_file, 'w', encoding='utf-8') as f:\n",
    "    for folder in folders:\n",
    "        target = folder.split(\"_\")[1]\n",
    "        f.write(target)\n",
    "        print(target)\n",
    "        if target != last:\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習リスト作成\n",
    "画像フォルダの構成から学習リストを作成する。\n",
    "画像ファイルを検索し、その画像に該当するアノテーションファイルを探す。\n",
    "\"画像ファイルパス　アノテーション\"のセットを1行としてファイルに書き出す。\n",
    "以下、このファイルを学習ファイルと呼ぶ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### モジュールインポート\n",
    "(後で切り出す用に上記と被るモジュールも記載)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定数宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dir = '../train_set/学習データ/479削除データ'\n",
    "train_file = 'train.txt'\n",
    "class_file = 'type_class.txt'\n",
    "img_dir = os.path.join(type_dir, 'image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = []\n",
    "with open(class_file, 'r', encoding='utf-8') as f:\n",
    "    class_list = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "error_list = []\n",
    "for path in glob.glob(os.path.join(img_dir, '*')):\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "    class_name = path.split(\"/\")[-1].split(\"_\")[1]\n",
    "    class_index = class_list.index(class_name)\n",
    "    print(class_index, class_name) \n",
    "    for file in glob.glob(os.path.join(path, '**', '*.jpg'),recursive=True):\n",
    "        annotation_file = file.replace(\"image\", \"annotation\").replace(\".jpg\", \".txt\")\n",
    "        if not os.path.isfile(annotation_file):\n",
    "            error_list.append(file)\n",
    "            continue\n",
    "            \n",
    "        with open(annotation_file, 'r', encoding='UTF-8') as f:\n",
    "            # Keras-yolo3のフォーマットに合わせる\n",
    "            # x_min, y_min, x_max, y_maxの順\n",
    "            line =  f.readline()\n",
    "            while line:\n",
    "                annotation = line.split(\" \")\n",
    "                x_min = annotation[0]\n",
    "                x_max = annotation[1]\n",
    "                y_min = annotation[2]\n",
    "                y_max = annotation[3]\n",
    "                train_list.append([file, x_min, y_min, x_max, y_max, str(class_index)])\n",
    "                line = f.readline()\n",
    "\n",
    "print(\"train_list:\",len(train_list))\n",
    "print(\"error_list:\",len(error_list))\n",
    "if error_list:\n",
    "    print(error_list)\n",
    "\n",
    "last = train_list[-1]\n",
    "with open(train_file, 'w', encoding='utf-8') as f:\n",
    "    for line in train_list:\n",
    "        jpg = line[0]\n",
    "        f.write(jpg+' ')\n",
    "        f.write(','.join(line[1:]))\n",
    "        if line != last:\n",
    "            f.write('\\n')\n",
    "print(\"file made:\",train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モジュールインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "from src.yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from src.yolo3.utils import get_random_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数追加\n",
    "とりあえずデフォルト設定で何もいじらず使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    #model_body = multi_gpu_model(model_body, gpus=2)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "    #model = multi_gpu_model(model, gpus=2)\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定数宣言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_path = 'train.txt' #学習リスト\n",
    "log_dir = 'logs/マルチモデル/' #アウトプット先ふぉるだ\n",
    "classes_path = 'type_class.txt' #クラスファイル\n",
    "anchors_path = 'model_data/yolo_anchors.txt' #これはyolo設定なのでとりあえずデフォルト\n",
    "first_weight = 'model_data/darknet53_weights.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ファイル等読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像のサイズを416x416とする\n",
    "input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "# モデルのインスタンス作成\n",
    "model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path=first_weight) # make sure you know what you freeze\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "\n",
    "# ある条件で学習をストップさせる設定\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "# 訓練データと検証データに分けるとこ(とりあえずランダムで9:1)\n",
    "val_split = 0.1\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines)*val_split)\n",
    "num_train = len(lines) - num_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルコンパイルして学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with frozen layers first, to get a stable loss.\n",
    "# Adjust num epochs to your dataset. This step is enough to obtain a not bad model.\n",
    "if True:\n",
    "    model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "        # use custom yolo_loss Lambda layer.\n",
    "        'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "\n",
    "    batch_size = 8\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    history = model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=10,\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint])\n",
    "    print(history)\n",
    "    model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "# Unfreeze and continue training, to fine-tune.\n",
    "# Train longer if the result is not good.\n",
    "if True:\n",
    "    #model = multi_gpu_model(model, gpus=2)\n",
    "    for i in range(len(model.layers)):\n",
    "        model.layers[i].trainable = True\n",
    "    model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "    print('Unfreeze all of the layers.')\n",
    "\n",
    "    batch_size = 8 # note that more GPU memory is required after unfreezing the body\n",
    "    print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=20,\n",
    "        initial_epoch=10,\n",
    "        callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "    model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "\n",
    "# Further training if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
